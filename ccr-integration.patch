From 16b8de546e40cd5cb550c503b673dbad821c3f1a Mon Sep 17 00:00:00 2001
From: Sedinha <luizsperandiodavid@gmail.com>
Date: Wed, 6 Aug 2025 23:18:43 -0300
Subject: [PATCH] feat: integrate claude-code-router for dynamic models

---
 scripts/ccr_wrapper.sh                 |   4 +
 src-tauri/src/claude_binary.rs         |  13 +
 src-tauri/src/commands/ccr.rs          |  60 +++++
 src-tauri/src/commands/mod.rs          |   1 +
 src-tauri/src/main.rs                  |   3 +
 src/components/ClaudeCodeSession.tsx   |  33 ++-
 src/components/FloatingPromptInput.tsx | 339 ++++++++-----------------
 src/lib/api.ts                         |  22 ++
 8 files changed, 232 insertions(+), 243 deletions(-)
 create mode 100755 scripts/ccr_wrapper.sh
 create mode 100644 src-tauri/src/commands/ccr.rs

diff --git a/scripts/ccr_wrapper.sh b/scripts/ccr_wrapper.sh
new file mode 100755
index 0000000..8f8d6dd
--- /dev/null
+++ b/scripts/ccr_wrapper.sh
@@ -0,0 +1,4 @@
+#!/bin/bash
+# This script acts as a bridge between Claudia and the ccr tool.
+# It takes all arguments passed to it and forwards them to "ccr code".
+/home/sedinha/.nvm/versions/node/v20.18.2/bin/ccr code "$@"
diff --git a/src-tauri/src/claude_binary.rs b/src-tauri/src/claude_binary.rs
index 272a1cc..356d191 100644
--- a/src-tauri/src/claude_binary.rs
+++ b/src-tauri/src/claude_binary.rs
@@ -146,6 +146,19 @@ fn source_preference(installation: &ClaudeInstallation) -> u8 {
 fn discover_system_installations() -> Vec<ClaudeInstallation> {
     let mut installations = Vec::new();
 
+    // Manually add ccr wrapper script path
+    let ccr_path = "/home/sedinha/Desktop/claudia/scripts/ccr_wrapper.sh".to_string();
+    if PathBuf::from(&ccr_path).exists() {
+        info!("Found ccr binary at: {}", ccr_path);
+        let version = get_claude_version(&ccr_path).ok().flatten();
+        installations.push(ClaudeInstallation {
+            path: ccr_path,
+            version,
+            source: "ccr".to_string(),
+            installation_type: InstallationType::Custom,
+        });
+    }
+
     // 1. Try 'which' command first (now works in production)
     if let Some(installation) = try_which_command() {
         installations.push(installation);
diff --git a/src-tauri/src/commands/ccr.rs b/src-tauri/src/commands/ccr.rs
new file mode 100644
index 0000000..836cb96
--- /dev/null
+++ b/src-tauri/src/commands/ccr.rs
@@ -0,0 +1,60 @@
+use serde::{Deserialize, Serialize};
+use std::fs;
+use log::{info, warn};
+
+#[derive(Debug, Deserialize, Serialize, Clone)]
+struct CcrProvider {
+    name: String,
+    models: Vec<String>,
+}
+
+#[derive(Debug, Deserialize, Serialize, Clone)]
+struct CcrRouter {
+    default: String,
+}
+
+#[derive(Debug, Deserialize, Serialize, Clone)]
+struct CcrConfig {
+    #[serde(rename = "Providers")]
+    providers: Vec<CcrProvider>,
+    #[serde(rename = "Router")]
+    router: CcrRouter,
+}
+
+#[derive(Debug, Serialize, Clone)]
+pub struct CcrModelInfo {
+    provider: String,
+    models: Vec<String>,
+    default_model: String,
+}
+
+#[tauri::command]
+pub fn get_ccr_model_info() -> Result<CcrModelInfo, String> {
+    info!("Attempting to read claude-code-router config");
+    let home_dir = dirs::home_dir().ok_or_else(|| "Could not find home directory".to_string())?;
+    let config_path = home_dir.join(".claude-code-router").join("config.json");
+
+    if !config_path.exists() {
+        let err_msg = format!("ccr config not found at {:?}", config_path);
+        warn!("{}", err_msg);
+        return Err(err_msg);
+    }
+
+    let config_content = fs::read_to_string(&config_path)
+        .map_err(|e| format!("Failed to read ccr config file: {}", e))?;
+
+    let config: CcrConfig = serde_json::from_str(&config_content)
+        .map_err(|e| format!("Failed to parse ccr config file: {}", e))?;
+
+    // Assuming the first provider is the one we want, as per the user's setup.
+    let provider = config.providers.get(0).ok_or_else(|| "No providers found in ccr config".to_string())?;
+
+    // The default model is in the format "provider,model_name". We need to extract the model name.
+    let default_model_name = config.router.default.split(',').nth(1).unwrap_or("").trim().to_string();
+
+    Ok(CcrModelInfo {
+        provider: provider.name.clone(),
+        models: provider.models.clone(),
+        default_model: default_model_name,
+    })
+}
diff --git a/src-tauri/src/commands/mod.rs b/src-tauri/src/commands/mod.rs
index a0fa7e8..d5392b6 100644
--- a/src-tauri/src/commands/mod.rs
+++ b/src-tauri/src/commands/mod.rs
@@ -5,3 +5,4 @@ pub mod usage;
 pub mod storage;
 pub mod slash_commands;
 pub mod proxy;
+pub mod ccr;
diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs
index 0589bef..9635413 100644
--- a/src-tauri/src/main.rs
+++ b/src-tauri/src/main.rs
@@ -249,6 +249,9 @@ fn main() {
             // Proxy Settings
             get_proxy_settings,
             save_proxy_settings,
+
+            // CCR Commands
+            commands::ccr::get_ccr_model_info,
         ])
         .run(tauri::generate_context!())
         .expect("error while running tauri application");
diff --git a/src/components/ClaudeCodeSession.tsx b/src/components/ClaudeCodeSession.tsx
index 20d32a0..779daaa 100644
--- a/src/components/ClaudeCodeSession.tsx
+++ b/src/components/ClaudeCodeSession.tsx
@@ -95,7 +95,7 @@ export const ClaudeCodeSession: React.FC<ClaudeCodeSessionProps> = ({
   const [forkSessionName, setForkSessionName] = useState("");
   
   // Queued prompts state
-  const [queuedPrompts, setQueuedPrompts] = useState<Array<{ id: string; prompt: string; model: "sonnet" | "opus" }>>([]);
+  const [queuedPrompts, setQueuedPrompts] = useState<Array<{ id: string; prompt: string; model: string }>>([]);
   
   // New state for preview feature
   const [showPreview, setShowPreview] = useState(false);
@@ -111,7 +111,7 @@ export const ClaudeCodeSession: React.FC<ClaudeCodeSessionProps> = ({
   const unlistenRefs = useRef<UnlistenFn[]>([]);
   const hasActiveSessionRef = useRef(false);
   const floatingPromptRef = useRef<FloatingPromptInputRef>(null);
-  const queuedPromptsRef = useRef<Array<{ id: string; prompt: string; model: "sonnet" | "opus" }>>([]);
+  const queuedPromptsRef = useRef<Array<{ id: string; prompt: string; model: string }>>([]);
   const isMountedRef = useRef(true);
   const isListeningRef = useRef(false);
   const sessionStartTime = useRef<number>(Date.now());
@@ -265,6 +265,25 @@ export const ClaudeCodeSession: React.FC<ClaudeCodeSessionProps> = ({
     onStreamingChange?.(isLoading, claudeSessionId);
   }, [isLoading, claudeSessionId, onStreamingChange]);
 
+  const handleModelChange = (provider: string, model: string) => {
+    const command = `/model ${provider},${model}`;
+    // We can't directly send a command without a user prompt.
+    // So, we add a user message to the history to show the change,
+    // and then we'll inject this command into the next `onSend` call.
+    // A better approach is to have a dedicated command channel.
+    // For now, let's just send it as a prompt.
+    handleSendPrompt(command, model);
+
+    // Add a visual confirmation in the chat
+    const modelChangeMessage: ClaudeStreamMessage = {
+      type: "system",
+      subtype: "info",
+      result: `Switched model to ${model}`,
+      timestamp: new Date().toISOString()
+    };
+    setMessages(prev => [...prev, modelChangeMessage]);
+  };
+
   // Auto-scroll to bottom when new messages arrive
   useEffect(() => {
     if (displayableMessages.length > 0) {
@@ -424,7 +443,7 @@ export const ClaudeCodeSession: React.FC<ClaudeCodeSessionProps> = ({
     }
   };
 
-  const handleSendPrompt = async (prompt: string, model: "sonnet" | "opus") => {
+  const handleSendPrompt = async (prompt: string, model: string) => {
     console.log('[ClaudeCodeSession] handleSendPrompt called with:', { prompt, model, projectPath, claudeSessionId, effectiveSession });
     
     if (!projectPath) {
@@ -432,6 +451,13 @@ export const ClaudeCodeSession: React.FC<ClaudeCodeSessionProps> = ({
       return;
     }
 
+    // If the prompt is a /model command, handle it separately
+    if (prompt.startsWith('/model ')) {
+      // This is now handled by onModelChange, but we can keep this as a manual fallback
+      // Or just let it be sent like a normal prompt, which ccr should handle.
+      // For now, we'll let it pass through as a normal prompt.
+    }
+
     // If already loading, queue the prompt
     if (isLoading) {
       const newPrompt = {
@@ -1560,6 +1586,7 @@ export const ClaudeCodeSession: React.FC<ClaudeCodeSessionProps> = ({
             <FloatingPromptInput
               ref={floatingPromptRef}
               onSend={handleSendPrompt}
+              onModelChange={handleModelChange}
               onCancel={handleCancelExecution}
               isLoading={isLoading}
               disabled={!projectPath}
diff --git a/src/components/FloatingPromptInput.tsx b/src/components/FloatingPromptInput.tsx
index be3507e..7c0a1d7 100644
--- a/src/components/FloatingPromptInput.tsx
+++ b/src/components/FloatingPromptInput.tsx
@@ -8,7 +8,8 @@ import {
   Sparkles,
   Zap,
   Square,
-  Brain
+  Brain,
+  Loader2,
 } from "lucide-react";
 import { cn } from "@/lib/utils";
 import { Button } from "@/components/ui/button";
@@ -18,37 +19,17 @@ import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from "@/comp
 import { FilePicker } from "./FilePicker";
 import { SlashCommandPicker } from "./SlashCommandPicker";
 import { ImagePreview } from "./ImagePreview";
-import { type FileEntry, type SlashCommand } from "@/lib/api";
+import { api, type FileEntry, type SlashCommand, type CcrModelInfo } from "@/lib/api";
 import { getCurrentWebviewWindow } from "@tauri-apps/api/webviewWindow";
 
 interface FloatingPromptInputProps {
-  /**
-   * Callback when prompt is sent
-   */
-  onSend: (prompt: string, model: "sonnet" | "opus") => void;
-  /**
-   * Whether the input is loading
-   */
+  onSend: (prompt: string, model: string) => void;
+  onModelChange?: (provider: string, model: string) => void;
   isLoading?: boolean;
-  /**
-   * Whether the input is disabled
-   */
   disabled?: boolean;
-  /**
-   * Default model to select
-   */
-  defaultModel?: "sonnet" | "opus";
-  /**
-   * Project path for file picker
-   */
+  defaultModel?: string;
   projectPath?: string;
-  /**
-   * Optional className for styling
-   */
   className?: string;
-  /**
-   * Callback when cancel is clicked (only during loading)
-   */
   onCancel?: () => void;
 }
 
@@ -56,114 +37,51 @@ export interface FloatingPromptInputRef {
   addImage: (imagePath: string) => void;
 }
 
-/**
- * Thinking mode type definition
- */
 type ThinkingMode = "auto" | "think" | "think_hard" | "think_harder" | "ultrathink";
 
-/**
- * Thinking mode configuration
- */
 type ThinkingModeConfig = {
   id: ThinkingMode;
   name: string;
   description: string;
-  level: number; // 0-4 for visual indicator
-  phrase?: string; // The phrase to append
+  level: number;
+  phrase?: string;
 };
 
 const THINKING_MODES: ThinkingModeConfig[] = [
-  {
-    id: "auto",
-    name: "Auto",
-    description: "Let Claude decide",
-    level: 0
-  },
-  {
-    id: "think",
-    name: "Think",
-    description: "Basic reasoning",
-    level: 1,
-    phrase: "think"
-  },
-  {
-    id: "think_hard",
-    name: "Think Hard",
-    description: "Deeper analysis",
-    level: 2,
-    phrase: "think hard"
-  },
-  {
-    id: "think_harder",
-    name: "Think Harder",
-    description: "Extensive reasoning",
-    level: 3,
-    phrase: "think harder"
-  },
-  {
-    id: "ultrathink",
-    name: "Ultrathink",
-    description: "Maximum computation",
-    level: 4,
-    phrase: "ultrathink"
-  }
+  { id: "auto", name: "Auto", description: "Let Claude decide", level: 0 },
+  { id: "think", name: "Think", description: "Basic reasoning", level: 1, phrase: "think" },
+  { id: "think_hard", name: "Think Hard", description: "Deeper analysis", level: 2, phrase: "think hard" },
+  { id: "think_harder", name: "Think Harder", description: "Extensive reasoning", level: 3, phrase: "think harder" },
+  { id: "ultrathink", name: "Ultrathink", description: "Maximum computation", level: 4, phrase: "ultrathink" },
 ];
 
-/**
- * ThinkingModeIndicator component - Shows visual indicator bars for thinking level
- */
-const ThinkingModeIndicator: React.FC<{ level: number }> = ({ level }) => {
-  return (
-    <div className="flex items-center gap-0.5">
-      {[1, 2, 3, 4].map((i) => (
-        <div
-          key={i}
-          className={cn(
-            "w-1 h-3 rounded-full transition-colors",
-            i <= level ? "bg-blue-500" : "bg-muted"
-          )}
-        />
-      ))}
-    </div>
-  );
-};
+const ThinkingModeIndicator: React.FC<{ level: number }> = ({ level }) => (
+  <div className="flex items-center gap-0.5">
+    {[1, 2, 3, 4].map((i) => (
+      <div
+        key={i}
+        className={cn("w-1 h-3 rounded-full transition-colors", i <= level ? "bg-blue-500" : "bg-muted")}
+      />
+    ))}
+  </div>
+);
 
 type Model = {
-  id: "sonnet" | "opus";
+  id: string;
   name: string;
   description: string;
   icon: React.ReactNode;
 };
 
-const MODELS: Model[] = [
-  {
-    id: "sonnet",
-    name: "Claude 4 Sonnet",
-    description: "Faster, efficient for most tasks",
-    icon: <Zap className="h-4 w-4" />
-  },
-  {
-    id: "opus",
-    name: "Claude 4 Opus",
-    description: "More capable, better for complex tasks",
-    icon: <Sparkles className="h-4 w-4" />
-  }
+const DEFAULT_MODELS: Model[] = [
+  { id: "sonnet", name: "Claude 4 Sonnet", description: "Faster, efficient for most tasks", icon: <Zap className="h-4 w-4" /> },
+  { id: "opus", name: "Claude 4 Opus", description: "More capable, better for complex tasks", icon: <Sparkles className="h-4 w-4" /> },
 ];
 
-/**
- * FloatingPromptInput component - Fixed position prompt input with model picker
- * 
- * @example
- * const promptRef = useRef<FloatingPromptInputRef>(null);
- * <FloatingPromptInput
- *   ref={promptRef}
- *   onSend={(prompt, model) => console.log('Send:', prompt, model)}
- *   isLoading={false}
- * />
- */
 const FloatingPromptInputInner = (
   {
     onSend,
+    onModelChange,
     isLoading = false,
     disabled = false,
     defaultModel = "sonnet",
@@ -174,7 +92,10 @@ const FloatingPromptInputInner = (
   ref: React.Ref<FloatingPromptInputRef>,
 ) => {
   const [prompt, setPrompt] = useState("");
-  const [selectedModel, setSelectedModel] = useState<"sonnet" | "opus">(defaultModel);
+  const [ccrInfo, setCcrInfo] = useState<CcrModelInfo | null>(null);
+  const [models, setModels] = useState<Model[]>(DEFAULT_MODELS);
+  const [selectedModel, setSelectedModel] = useState<string>(defaultModel);
+  const [isCcrLoading, setIsCcrLoading] = useState(true);
   const [selectedThinkingMode, setSelectedThinkingMode] = useState<ThinkingMode>("auto");
   const [isExpanded, setIsExpanded] = useState(false);
   const [modelPickerOpen, setModelPickerOpen] = useState(false);
@@ -191,28 +112,45 @@ const FloatingPromptInputInner = (
   const expandedTextareaRef = useRef<HTMLTextAreaElement>(null);
   const unlistenDragDropRef = useRef<(() => void) | null>(null);
 
-  // Expose a method to add images programmatically
+  useEffect(() => {
+    const fetchCcrInfo = async () => {
+      try {
+        setIsCcrLoading(true);
+        const info = await api.getCcrModelInfo();
+        setCcrInfo(info);
+        const ccrModels: Model[] = info.models.map(m => ({
+          id: m,
+          name: m,
+          description: `From ${info.provider}`,
+          icon: <Sparkles className="h-4 w-4" />
+        }));
+        setModels(ccrModels);
+        setSelectedModel(info.default_model || ccrModels[0]?.id || defaultModel);
+      } catch (error) {
+        console.warn("Could not load claude-code-router config, falling back to default models.", error);
+        setModels(DEFAULT_MODELS);
+        setSelectedModel(defaultModel);
+      } finally {
+        setIsCcrLoading(false);
+      }
+    };
+    fetchCcrInfo();
+  }, [defaultModel]);
+
   React.useImperativeHandle(
     ref,
     () => ({
       addImage: (imagePath: string) => {
         setPrompt(currentPrompt => {
           const existingPaths = extractImagePaths(currentPrompt);
-          if (existingPaths.includes(imagePath)) {
-            return currentPrompt; // Image already added
-          }
-
-          // Wrap path in quotes if it contains spaces
+          if (existingPaths.includes(imagePath)) return currentPrompt;
           const mention = imagePath.includes(' ') ? `@"${imagePath}"` : `@${imagePath}`;
           const newPrompt = currentPrompt + (currentPrompt.endsWith(' ') || currentPrompt === '' ? '' : ' ') + mention + ' ';
-
-          // Focus the textarea
           setTimeout(() => {
             const target = isExpanded ? expandedTextareaRef.current : textareaRef.current;
             target?.focus();
             target?.setSelectionRange(newPrompt.length, newPrompt.length);
           }, 0);
-
           return newPrompt;
         });
       }
@@ -220,139 +158,66 @@ const FloatingPromptInputInner = (
     [isExpanded]
   );
 
-  // Helper function to check if a file is an image
   const isImageFile = (path: string): boolean => {
-    // Check if it's a data URL
-    if (path.startsWith('data:image/')) {
-      return true;
-    }
-    // Otherwise check file extension
+    if (path.startsWith('data:image/')) return true;
     const ext = path.split('.').pop()?.toLowerCase();
     return ['png', 'jpg', 'jpeg', 'gif', 'svg', 'webp', 'ico', 'bmp'].includes(ext || '');
   };
 
-  // Extract image paths from prompt text
   const extractImagePaths = (text: string): string[] => {
-    console.log('[extractImagePaths] Input text length:', text.length);
-    
-    // Updated regex to handle both quoted and unquoted paths
-    // Pattern 1: @"path with spaces or data URLs" - quoted paths
-    // Pattern 2: @path - unquoted paths (continues until @ or end)
     const quotedRegex = /@"([^"]+)"/g;
     const unquotedRegex = /@([^@\n\s]+)/g;
-    
-    const pathsSet = new Set<string>(); // Use Set to ensure uniqueness
-    
-    // First, extract quoted paths (including data URLs)
+    const pathsSet = new Set<string>();
     let matches = Array.from(text.matchAll(quotedRegex));
-    console.log('[extractImagePaths] Quoted matches:', matches.length);
-    
     for (const match of matches) {
-      const path = match[1]; // No need to trim, quotes preserve exact path
-      console.log('[extractImagePaths] Processing quoted path:', path.startsWith('data:') ? 'data URL' : path);
-      
-      // For data URLs, use as-is; for file paths, convert to absolute
-      const fullPath = path.startsWith('data:') 
-        ? path 
-        : (path.startsWith('/') ? path : (projectPath ? `${projectPath}/${path}` : path));
-      
-      if (isImageFile(fullPath)) {
-        pathsSet.add(fullPath);
-      }
+      const path = match[1];
+      const fullPath = path.startsWith('data:') ? path : (path.startsWith('/') ? path : (projectPath ? `${projectPath}/${path}` : path));
+      if (isImageFile(fullPath)) pathsSet.add(fullPath);
     }
-    
-    // Remove quoted mentions from text to avoid double-matching
     let textWithoutQuoted = text.replace(quotedRegex, '');
-    
-    // Then extract unquoted paths (typically file paths)
     matches = Array.from(textWithoutQuoted.matchAll(unquotedRegex));
-    console.log('[extractImagePaths] Unquoted matches:', matches.length);
-    
     for (const match of matches) {
       const path = match[1].trim();
-      // Skip if it looks like a data URL fragment (shouldn't happen with proper quoting)
       if (path.includes('data:')) continue;
-      
-      console.log('[extractImagePaths] Processing unquoted path:', path);
-      
-      // Convert relative path to absolute if needed
       const fullPath = path.startsWith('/') ? path : (projectPath ? `${projectPath}/${path}` : path);
-      
-      if (isImageFile(fullPath)) {
-        pathsSet.add(fullPath);
-      }
+      if (isImageFile(fullPath)) pathsSet.add(fullPath);
     }
-
-    const uniquePaths = Array.from(pathsSet);
-    console.log('[extractImagePaths] Final extracted paths (unique):', uniquePaths.length);
-    return uniquePaths;
+    return Array.from(pathsSet);
   };
 
-  // Update embedded images when prompt changes
   useEffect(() => {
-    console.log('[useEffect] Prompt changed:', prompt);
     const imagePaths = extractImagePaths(prompt);
-    console.log('[useEffect] Setting embeddedImages to:', imagePaths);
     setEmbeddedImages(imagePaths);
   }, [prompt, projectPath]);
 
-  // Set up Tauri drag-drop event listener
   useEffect(() => {
-    // This effect runs only once on component mount to set up the listener.
     let lastDropTime = 0;
-
     const setupListener = async () => {
       try {
-        // If a listener from a previous mount/render is still around, clean it up.
-        if (unlistenDragDropRef.current) {
-          unlistenDragDropRef.current();
-        }
-
+        if (unlistenDragDropRef.current) unlistenDragDropRef.current();
         const webview = getCurrentWebviewWindow();
         unlistenDragDropRef.current = await webview.onDragDropEvent((event) => {
-          if (event.payload.type === 'enter' || event.payload.type === 'over') {
-            setDragActive(true);
-          } else if (event.payload.type === 'leave') {
+          if (event.payload.type === 'enter' || event.payload.type === 'over') setDragActive(true);
+          else if (event.payload.type === 'leave') setDragActive(false);
+          else if (event.payload.type === 'drop' && event.payload.paths) {
             setDragActive(false);
-          } else if (event.payload.type === 'drop' && event.payload.paths) {
-            setDragActive(false);
-
             const currentTime = Date.now();
-            if (currentTime - lastDropTime < 200) {
-              // This debounce is crucial to handle the storm of drop events
-              // that Tauri/OS can fire for a single user action.
-              return;
-            }
+            if (currentTime - lastDropTime < 200) return;
             lastDropTime = currentTime;
-
             const droppedPaths = event.payload.paths as string[];
             const imagePaths = droppedPaths.filter(isImageFile);
-
             if (imagePaths.length > 0) {
               setPrompt(currentPrompt => {
                 const existingPaths = extractImagePaths(currentPrompt);
                 const newPaths = imagePaths.filter(p => !existingPaths.includes(p));
-
-                if (newPaths.length === 0) {
-                  return currentPrompt; // All dropped images are already in the prompt
-                }
-
-                // Wrap paths with spaces in quotes for clarity
-                const mentionsToAdd = newPaths.map(p => {
-                  // If path contains spaces, wrap in quotes
-                  if (p.includes(' ')) {
-                    return `@"${p}"`;
-                  }
-                  return `@${p}`;
-                }).join(' ');
+                if (newPaths.length === 0) return currentPrompt;
+                const mentionsToAdd = newPaths.map(p => p.includes(' ') ? `@"${p}"` : `@${p}`).join(' ');
                 const newPrompt = currentPrompt + (currentPrompt.endsWith(' ') || currentPrompt === '' ? '' : ' ') + mentionsToAdd + ' ';
-
                 setTimeout(() => {
                   const target = isExpanded ? expandedTextareaRef.current : textareaRef.current;
                   target?.focus();
                   target?.setSelectionRange(newPrompt.length, newPrompt.length);
                 }, 0);
-
                 return newPrompt;
               });
             }
@@ -362,43 +227,40 @@ const FloatingPromptInputInner = (
         console.error('Failed to set up Tauri drag-drop listener:', error);
       }
     };
-
     setupListener();
-
     return () => {
-      // On unmount, ensure we clean up the listener.
       if (unlistenDragDropRef.current) {
         unlistenDragDropRef.current();
         unlistenDragDropRef.current = null;
       }
     };
-  }, []); // Empty dependency array ensures this runs only on mount/unmount.
+  }, []);
 
   useEffect(() => {
-    // Focus the appropriate textarea when expanded state changes
-    if (isExpanded && expandedTextareaRef.current) {
-      expandedTextareaRef.current.focus();
-    } else if (!isExpanded && textareaRef.current) {
-      textareaRef.current.focus();
-    }
+    if (isExpanded && expandedTextareaRef.current) expandedTextareaRef.current.focus();
+    else if (!isExpanded && textareaRef.current) textareaRef.current.focus();
   }, [isExpanded]);
 
   const handleSend = () => {
     if (prompt.trim() && !disabled) {
       let finalPrompt = prompt.trim();
-      
-      // Append thinking phrase if not auto mode
       const thinkingMode = THINKING_MODES.find(m => m.id === selectedThinkingMode);
-      if (thinkingMode && thinkingMode.phrase) {
-        finalPrompt = `${finalPrompt}.\n\n${thinkingMode.phrase}.`;
-      }
-      
+      if (thinkingMode && thinkingMode.phrase) finalPrompt = `${finalPrompt}.\n\n${thinkingMode.phrase}.`;
       onSend(finalPrompt, selectedModel);
       setPrompt("");
       setEmbeddedImages([]);
     }
   };
 
+  const handleModelSelect = (modelId: string) => {
+    setSelectedModel(modelId);
+    setModelPickerOpen(false);
+    if (onModelChange && ccrInfo) {
+      onModelChange(ccrInfo.provider, modelId);
+    }
+  };
+
+  // ... (keep the rest of the handlers: handleTextChange, handleFileSelect, etc. as they were)
   const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
     const newValue = e.target.value;
     const newCursorPosition = e.target.selectionStart || 0;
@@ -688,19 +550,19 @@ const FloatingPromptInputInner = (
     }
     
     // For file paths, use the original logic
-    const escapedPath = imagePath.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
-    const escapedRelativePath = imagePath.replace(projectPath + '/', '').replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
+    const escapedPath = imagePath.replace(/[.*+?^${}()|[\\]/g, '\\$&');
+    const escapedRelativePath = imagePath.replace(projectPath + '/', '').replace(/[.*+?^${}()|[\\]/g, '\\$&');
     
     // Create patterns for both quoted and unquoted mentions
     const patterns = [
       // Quoted full path
-      new RegExp(`@"${escapedPath}"\\s?`, 'g'),
+      new RegExp(`@"${escapedPath}"\s?`, 'g'),
       // Unquoted full path
-      new RegExp(`@${escapedPath}\\s?`, 'g'),
+      new RegExp(`@${escapedPath}\s?`, 'g'),
       // Quoted relative path
-      new RegExp(`@"${escapedRelativePath}"\\s?`, 'g'),
+      new RegExp(`@"${escapedRelativePath}"\s?`, 'g'),
       // Unquoted relative path
-      new RegExp(`@${escapedRelativePath}\\s?`, 'g')
+      new RegExp(`@${escapedRelativePath}\s?`)
     ];
 
     let newPrompt = prompt;
@@ -711,7 +573,7 @@ const FloatingPromptInputInner = (
     setPrompt(newPrompt.trim());
   };
 
-  const selectedModelData = MODELS.find(m => m.id === selectedModel) || MODELS[0];
+  const selectedModelData = models.find(m => m.id === selectedModel) || models[0] || DEFAULT_MODELS[0];
 
   return (
     <>
@@ -893,23 +755,20 @@ const FloatingPromptInputInner = (
                   <Button
                     variant="outline"
                     size="default"
-                    disabled={disabled}
+                    disabled={disabled || isCcrLoading}
                     className="gap-2 min-w-[180px] justify-start"
                   >
-                    {selectedModelData.icon}
-                    <span className="flex-1 text-left">{selectedModelData.name}</span>
+                    {isCcrLoading ? <Loader2 className="h-4 w-4 animate-spin" /> : selectedModelData.icon}
+                    <span className="flex-1 text-left">{isCcrLoading ? "Loading..." : selectedModelData.name}</span>
                     <ChevronUp className="h-4 w-4 opacity-50" />
                   </Button>
                 }
                 content={
-                  <div className="w-[300px] p-1">
-                    {MODELS.map((model) => (
+                  <div className="w-[300px] p-1 max-h-60 overflow-y-auto">
+                    {models.map((model) => (
                       <button
                         key={model.id}
-                        onClick={() => {
-                          setSelectedModel(model.id);
-                          setModelPickerOpen(false);
-                        }}
+                        onClick={() => handleModelSelect(model.id)}
                         className={cn(
                           "w-full flex items-start gap-3 p-3 rounded-md transition-colors text-left",
                           "hover:bg-accent",
@@ -1079,4 +938,4 @@ export const FloatingPromptInput = React.forwardRef<
   FloatingPromptInputProps
 >(FloatingPromptInputInner);
 
-FloatingPromptInput.displayName = 'FloatingPromptInput';
+FloatingPromptInput.displayName = 'FloatingPromptInput';
\ No newline at end of file
diff --git a/src/lib/api.ts b/src/lib/api.ts
index 9a78640..15ca4ee 100644
--- a/src/lib/api.ts
+++ b/src/lib/api.ts
@@ -440,10 +440,32 @@ export interface ImportServerResult {
   error?: string;
 }
 
+/**
+ * Represents the claude-code-router model info
+ */
+export interface CcrModelInfo {
+  provider: string;
+  models: string[];
+  default_model: string;
+}
+
 /**
  * API client for interacting with the Rust backend
  */
 export const api = {
+  /**
+   * Gets the claude-code-router model info
+   * @returns Promise resolving to the ccr model info
+   */
+  async getCcrModelInfo(): Promise<CcrModelInfo> {
+    try {
+      return await invoke<CcrModelInfo>("get_ccr_model_info");
+    } catch (error) {
+      console.error("Failed to get ccr model info:", error);
+      throw error;
+    }
+  },
+
   /**
    * Lists all projects in the ~/.claude/projects directory
    * @returns Promise resolving to an array of projects
-- 
2.50.1

